#!/usr/bin/env/ python

import requests,re,urlparse
class scanner:
    def __init__(self,url):
        self.target_url=url
        self.target_links =[]
    
    def extract_links(self,url):
        response = requests.get(url)
        return re.findall('(?:href=")(.*?)"',response.content)

    def crawl(self,url):
        href_links= self.extract_links(url)
        for links in href_links:
            link= urlparse.urljoin(url,links)

            if '#' in link:
                link = link.split('#')[0]
            
            if self.target_url in link and link not in self.target_links:
                target_links.append(links)
                print(link)
                print("\n")
                self.crawl(link)


